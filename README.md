# NSFW Validator

This Kotlin project provides an NSFW (Not Safe For Work) validator to filter out pornographic images. The project uses machine learning to detect inappropriate content in images and flag them accordingly.

## Features

- Detects and filters pornographic images.
- Provides a simple API for image validation.
- Can be integrated with Android applications.

## Download

 [AAB](./Build/NSFWValidator.aab)
 [APK](./Build/NSFWValidator.apk)
 
## Usage

| No. | Screen Shot | Description |
|---------|---------|---------|
| 1.   | ![Logo](./Object/qemu-system-x86_64_1ntycklYAl.png)| index layout    |
| 2.   | ![Logo](./Object/qemu-system-x86_64_vHAb6yH4Jw.png)| Storage Permission    |
| 3.   | ![Logo](./Object/qemu-system-x86_64_BqMZuap1JZ.png)| List of Image/Photos    |
| 4.   | ![Logo](./Object/qemu-system-x86_64_XUzYHJ6ScI.png)| Select Image/Photos    |
| 5.   | ![Logo](./Object/qemu-system-x86_64_1xfE9nPMKW.png)| View Image/Photos    |
| 6.   | ![Logo](./Object/qemu-system-x86_64_Mxt0q9fXFo.png)| Detect if the image contain Sexual Content    |
